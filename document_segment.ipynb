{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386484d7-c5f6-4cb0-91d9-15d4cbfa6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tiktoken==0.3.3\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3ef22-ee2f-4a77-852a-60e35bf59270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a83dd3e-6cca-41a4-9f46-edd58f0d70df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import requests\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04673699-30d1-464e-9893-d13567513833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81fa92e-ea6d-4ae7-bc5f-2d5626dbbdda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOC_DIR_PATH = './docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf601ed-f45b-453c-9205-308461ec520a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2b9e5d-d510-4c45-b191-6063eecdef6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_doc(doc: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of tokens in a text string.\n",
    "    \"\"\"\n",
    "    num_tokens = len(encoding.encode(doc))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eaf1764-5409-4040-89e2-ddf0a3c21c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94711ba2-d2e7-4dec-9a2c-02c895ca8051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_iterator(dir_path: str):\n",
    "    for root, _, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.read()\n",
    "                    yield filename, file_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f56825-da4e-4b1a-8969-765b596d318a",
   "metadata": {},
   "source": [
    "按照token切分文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65b6825-a183-46ea-a524-31857fcbdd78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48c3ad-cee4-417a-bba4-fe68f25db3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_docs = 0\n",
    "n_passages = 0\n",
    "\n",
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    print(f\"doc_name: {doc_name}\")\n",
    "    doc_id = doc_name.split('.')[0]\n",
    "    tokens = tokenizer.encode(doc)\n",
    "    chunks = []\n",
    "    chunk_id = 1\n",
    "    n_docs += 1\n",
    "    for i in range(0, len(tokens), CHUNK_SIZE):\n",
    "        chunk_tokens = tokens[i: i+CHUNK_SIZE]\n",
    "        if not len(chunk_tokens) < 256:\n",
    "            chunk = tokenizer.decode(chunk_tokens)\n",
    "            with open(f'./chunks/{doc_id}_{chunk_id}', 'w') as f:\n",
    "                f.write(chunk)\n",
    "            chunk_id += 1\n",
    "            n_passages += 1\n",
    "logger.info(f'{n_docs} documents segmented into {n_passages} passages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a647d8d0-2eb5-4385-b3d2-6934804ac5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = \"st-paraphrase-mpnet-base-v2-2023-04-14-04-17-29-625-endpoint\"\n",
    "\n",
    "def get_embedding(smr_client, text_input):\n",
    "    parameters = {\n",
    "      #\"early_stopping\": True,\n",
    "      #\"length_penalty\": 2.0,\n",
    "      \"max_new_tokens\": 50,\n",
    "      \"temperature\": 0,\n",
    "      \"min_length\": 10,\n",
    "      \"no_repeat_ngram_size\": 2,\n",
    "    }\n",
    "\n",
    "    response_model = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                Body=json.dumps(\n",
    "                {\n",
    "                    \"inputs\": [text_input],\n",
    "                    \"parameters\": parameters\n",
    "                }\n",
    "                ),\n",
    "                ContentType=\"application/json\",\n",
    "            )\n",
    "    \n",
    "    return response_model['Body'].read().decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80113f6-b408-422e-b56c-1a4dd1130053",
   "metadata": {
    "tags": []
   },
   "source": [
    "测试paraphrase-mpnet-base-v2的setence2embedding模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "908bebd0-9667-49e6-96a3-f44aa2326c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def parseJson2vector(input:str):\n",
    "    \"\"\"\n",
    "    Parse Json string, and extract key \"sentence_embeddings\" to get the vector string, then convert it to numpy array\n",
    "    \"\"\"\n",
    "    json_obj = json.loads(input)\n",
    "    vector_array = json_obj[\"sentence_embeddings\"]\n",
    "    return vector_array\n",
    "\n",
    "def calulate_cosine(vector1,vector2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "    return np.dot(vector1,vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2))\n",
    "\n",
    "def calulate_cosine_between_sentence_pair(smr_client, q_str, a_str):\n",
    "    q_vec = parseJson2vector(get_embedding(smr_client, q_str))[0]\n",
    "    a_vec = parseJson2vector(get_embedding(smr_client, a_str))[0]\n",
    "    return calulate_cosine(q_vec, a_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6f764-4cef-46a2-a20b-f110e2886081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_line = \"\"\n",
    "            for a_idx, a_line in enumerate(a_lines):\n",
    "                cos_val = calulate_cosine_between_sentence_pair(smr_client, q_line, a_line)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_line = a_line\n",
    "            print(f'{max_cos} | {q_line} | {max_a_line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709543b-2c99-4750-80f3-ebbeacec07f5",
   "metadata": {},
   "source": [
    "测试bloomz的setence2embedding 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5162f-9d2f-442e-a00d-de4c434e5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_EMBEDDING_MODEL_ENDPOINT_NAME='huggingface-textembedding-bloom-7b1-fp1-2023-04-13-11-29-28-700'\n",
    "\n",
    "def get_bloomz_embedding(smr_client, text_input):\n",
    "    payload = {'text_inputs': [text_input]}\n",
    "    payload = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "    response = smr_client.invoke_endpoint(EndpointName=TEXT_EMBEDDING_MODEL_ENDPOINT_NAME, \n",
    "                                                ContentType='application/json', \n",
    "                                                Body=payload)\n",
    "    body = json.loads(response['Body'].read())\n",
    "    embedding = body['embedding'][0]\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07863da6-1172-4a40-abf4-122f22b28046",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bloomz_embedding(smr_client, '请问AWS Clean Rooms的一个协作中可以有多少个参与方?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc513b8-6957-4394-8f91-7f354b321b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calulate_cosine_between_sentence_pair2(smr_client, q_str, a_str):\n",
    "    q_vec = get_bloomz_embedding(smr_client, q_str)\n",
    "    a_vec = get_bloomz_embedding(smr_client, a_str)\n",
    "    return calulate_cosine(q_vec, a_vec)\n",
    "\n",
    "CHUNK_DIR_PATH='./chunks'\n",
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_doc = \"\"\n",
    "            for doc_name, a_doc in tqdm(doc_iterator(CHUNK_DIR_PATH)):\n",
    "                cos_val = calulate_cosine_between_sentence_pair2(smr_client, q_line, a_doc)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_doc = a_doc\n",
    "            print(f'{max_cos} | {q_line} | {max_a_doc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf55d6-c4cb-4966-a59e-13515fd5e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
