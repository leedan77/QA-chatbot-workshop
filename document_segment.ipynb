{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386484d7-c5f6-4cb0-91d9-15d4cbfa6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tiktoken==0.3.3\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3ef22-ee2f-4a77-852a-60e35bf59270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a83dd3e-6cca-41a4-9f46-edd58f0d70df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import requests\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04673699-30d1-464e-9893-d13567513833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "DOC_DIR_PATH = './docs'\n",
    "CHUNK_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa40ad3c-84b3-4bc1-b887-4e7caa92b3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tiktoken.core.Encoding"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf601ed-f45b-453c-9205-308461ec520a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94711ba2-d2e7-4dec-9a2c-02c895ca8051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_iterator(dir_path: str):\n",
    "    for root, _, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.read()\n",
    "                    yield filename, file_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f56825-da4e-4b1a-8969-765b596d318a",
   "metadata": {},
   "source": [
    "### 按照token等长切分文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65b6825-a183-46ea-a524-31857fcbdd78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd48c3ad-cee4-417a-bba4-fe68f25db3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment_doc_by_token_length(input_path, tokenizer):\n",
    "    n_docs = 0\n",
    "    n_passages = 0\n",
    "\n",
    "    for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "        print(f\"doc_name: {doc_name}\")\n",
    "        doc_id = doc_name.split('.')[0]\n",
    "        tokens = tokenizer.encode(doc)\n",
    "        chunks = []\n",
    "        chunk_id = 1\n",
    "        n_docs += 1\n",
    "        for i in range(0, len(tokens), CHUNK_SIZE):\n",
    "            chunk_tokens = tokens[i: i+CHUNK_SIZE]\n",
    "            if not len(chunk_tokens) < 256:\n",
    "                chunk = tokenizer.decode(chunk_tokens)\n",
    "                with open(f'./chunks/{doc_id}_{chunk_id}', 'w') as f:\n",
    "                    f.write(chunk)\n",
    "                chunk_id += 1\n",
    "                n_passages += 1\n",
    "    logger.info(f'{n_docs} documents segmented into {n_passages} passages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66dcd827-9c0e-45af-8f5f-f0e875ce0f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_name: Cleanroom_FAQ.txt\n",
      "doc_name: Cleanroom_FAQ-checkpoint.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.14it/s]\n",
      "2 documents segmented into 30 passages\n"
     ]
    }
   ],
   "source": [
    "segment_doc_by_token_length('./docs', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a647d8d0-2eb5-4385-b3d2-6934804ac5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "def get_st_embedding(smr_client, text_input):\n",
    "    endpoint_name = \"st-paraphrase-mpnet-base-v2-2023-04-14-04-17-29-625-endpoint\"\n",
    "    parameters = {\n",
    "      #\"early_stopping\": True,\n",
    "      #\"length_penalty\": 2.0,\n",
    "      \"max_new_tokens\": 50,\n",
    "      \"temperature\": 0,\n",
    "      \"min_length\": 10,\n",
    "      \"no_repeat_ngram_size\": 2,\n",
    "    }\n",
    "\n",
    "    response_model = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                Body=json.dumps(\n",
    "                {\n",
    "                    \"inputs\": [text_input],\n",
    "                    \"parameters\": parameters\n",
    "                }\n",
    "                ),\n",
    "                ContentType=\"application/json\",\n",
    "            )\n",
    "    \n",
    "    json_str = response_model['Body'].read().decode('utf8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    embeddings = json_obj[\"sentence_embeddings\"]\n",
    "    \n",
    "    return embeddings[0]\n",
    "\n",
    "def get_bloom_embedding(smr_client, text_input):\n",
    "    TEXT_EMBEDDING_MODEL_ENDPOINT_NAME='huggingface-textembedding-bloom-7b1-fp1-2023-04-13-11-29-28-700'\n",
    "    payload = {'text_inputs': [text_input]}\n",
    "    payload = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "    response = smr_client.invoke_endpoint(EndpointName=TEXT_EMBEDDING_MODEL_ENDPOINT_NAME, \n",
    "                                                ContentType='application/json', \n",
    "                                                Body=payload)\n",
    "    body = json.loads(response['Body'].read())\n",
    "    embedding = body['embedding'][0]\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def calulate_cosine(vector1,vector2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "    return np.dot(vector1,vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2))\n",
    "\n",
    "def calulate_semantic_distance(smr_client, q_str, a_str, get_emb_func):\n",
    "    q_vec = get_emb_func(smr_client, q_str)\n",
    "    a_vec = get_emb_func(smr_client, a_str)\n",
    "    return calulate_cosine(q_vec, a_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80113f6-b408-422e-b56c-1a4dd1130053",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 按照Question&Answer Pair 测试paraphrase-mpnet-base-v2的语义召回能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6f764-4cef-46a2-a20b-f110e2886081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_line = \"\"\n",
    "            for a_idx, a_line in enumerate(a_lines):\n",
    "                cos_val = calulate_semantic_distance(smr_client, q_line, a_line, get_st_embedding)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_line = a_line\n",
    "            print(f'{max_cos} | {q_line} | {max_a_line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709543b-2c99-4750-80f3-ebbeacec07f5",
   "metadata": {},
   "source": [
    "### 按照Question&Answer Pair 测试bloom的语义召回能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5162f-9d2f-442e-a00d-de4c434e5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_line = \"\"\n",
    "            for a_idx, a_line in enumerate(a_lines):\n",
    "                cos_val = calulate_semantic_distance(smr_client, q_line, a_line, get_bloom_embedding)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_line = a_line\n",
    "            print(f'{max_cos} | {q_line} | {max_a_line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ec4b3-6cb8-4f8d-87ca-98580d29c945",
   "metadata": {},
   "source": [
    "### 按照Question&Chunk 测试paraphrase-mpnet-base-v2的语义召回能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc513b8-6957-4394-8f91-7f354b321b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHUNK_DIR_PATH='./chunks'\n",
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_doc = \"\"\n",
    "            for doc_name, a_doc in tqdm(doc_iterator(CHUNK_DIR_PATH)):\n",
    "                cos_val = calulate_semantic_distance(smr_client, q_line, a_doc, get_st_embedding)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_doc = a_doc\n",
    "            print(f'{max_cos} | {q_line} | {max_a_doc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937eefde-fbb0-4d62-ab9b-7f8e0c151a14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 按照Question&Chunk 测试bloom的语义召回能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c5354-5575-4acd-9745-7c4fd330769a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHUNK_DIR_PATH='./chunks'\n",
    "for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "    if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "        lines = doc.splitlines()\n",
    "        q_lines = [ line for line in lines if line.startswith('Question') ]\n",
    "        a_lines = [ line for line in lines if line.startswith('Answer') ]\n",
    "        for q_idx, q_line in enumerate(q_lines):\n",
    "            max_cos = 0.0\n",
    "            max_a_doc = \"\"\n",
    "            for doc_name, a_doc in tqdm(doc_iterator(CHUNK_DIR_PATH)):\n",
    "                cos_val = calulate_semantic_distance(smr_client, q_line, a_doc, get_bloom_embedding)\n",
    "                if cos_val > max_cos:\n",
    "                    max_cos = cos_val\n",
    "                    max_a_doc = a_doc\n",
    "            print(f'{max_cos} | {q_line} | {max_a_doc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca5477-d45a-45d1-a0b9-672b2cc5a6b1",
   "metadata": {},
   "source": [
    "### 按照段落进行分组(Token Size 限制)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4cf55d6-c4cb-4966-a59e-13515fd5e374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment_doc_by_paragraph(input_path, tokenizer):\n",
    "    paragraphs = []\n",
    "    paragraph_embeddings = []\n",
    "    q_line_vec_arr = []\n",
    "\n",
    "    for doc_name, doc in tqdm(doc_iterator(DOC_DIR_PATH)):\n",
    "        if doc_name == \"Cleanroom_FAQ.txt\":\n",
    "            lines = doc.splitlines()\n",
    "            max_len = len(lines)\n",
    "            print(f\"max_len : {max_len}\")\n",
    "\n",
    "            q_line_vec_arr = [ (line, get_st_embedding(smr_client, line)) for line in lines if line.startswith('Question') ]\n",
    "\n",
    "            for line_idx in range(len(lines)):\n",
    "                if lines[line_idx] == '':\n",
    "                    continue\n",
    "                span = 0\n",
    "                len_token = 0\n",
    "                while len_token < 128:\n",
    "                    # print(f\"line_idx+span : {line_idx+span}, span : {span}\")\n",
    "                    delta_token_len = len(tokenizer.encode(lines[line_idx+span]))\n",
    "                    span += 1\n",
    "                    if line_idx+span == max_len:\n",
    "                        break\n",
    "                    len_token += delta_token_len\n",
    "\n",
    "                paragraph = '\\n'.join(lines[line_idx:line_idx+span])\n",
    "                paragraphs.append(paragraph)\n",
    "                paragraph_emb = get_st_embedding(smr_client, paragraph)\n",
    "                # print(paragraph_emb)\n",
    "                paragraph_embeddings.append(paragraph_emb)\n",
    "                \n",
    "    return paragraphs, paragraph_embeddings, q_line_vec_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "009ece9a-3904-43d7-98aa-896f4325a9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paragraphs, paragraph_embeddings, q_line_vec_arr = segment_doc_by_paragraph('./docs', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dfa45-5f7c-4ff1-a2cb-a1eae1af5074",
   "metadata": {},
   "source": [
    "### 按照Question&Paragraph 测试paraphrase-mpnet-base-v2的语义召回能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f988cc-5a7d-4088-bfdc-b9682c7a83fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"start to calulate similiarity\")\n",
    "for q_doc, q_vec in q_line_vec_arr:\n",
    "    max_cos = 0.0\n",
    "    a_doc = \"\"\n",
    "    for idx in range(len(paragraphs)):\n",
    "        cos_val = calulate_cosine(q_vec, paragraph_embeddings[idx])\n",
    "        if cos_val > max_cos:\n",
    "            max_cos = cos_val\n",
    "            a_doc = paragraphs[idx]\n",
    "    print(f\"***{q_doc}***\\n{a_doc}\\n[score]:{max_cos}\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81230658-a103-4d38-b9c2-4ca50cfe64b5",
   "metadata": {},
   "source": [
    "### 存贮段落到磁盘进行搜索分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece17b3-bde9-45f8-a770-1ff4e8b67eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089206ae-f779-4271-8ac0-a7e1dda23a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把这些paragraphs写入文件\n",
    "for idx, paragraph in enumerate(paragraphs):\n",
    "    with open(f'./paragraphs/{idx}.txt', 'w') as f:\n",
    "        f.write(paragraph)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
